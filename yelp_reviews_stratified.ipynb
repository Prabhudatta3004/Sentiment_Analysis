{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3316532,"sourceType":"datasetVersion","datasetId":10100}],"dockerImageVersionId":30558,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import json\nimport pandas as pd\nimport nltk\nfrom gensim.models import Word2Vec\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.metrics import accuracy_score, classification_report","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-20T16:40:45.085968Z","iopub.execute_input":"2023-11-20T16:40:45.086935Z","iopub.status.idle":"2023-11-20T16:40:59.443014Z","shell.execute_reply.started":"2023-11-20T16:40:45.086885Z","shell.execute_reply":"2023-11-20T16:40:59.441779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_file = open(\"/kaggle/input/yelp-dataset/yelp_academic_dataset_review.json\")\ndata = []\ndata_cnt = 0\nfor line in data_file:\n    data.append(json.loads(line))\n    data_cnt += 1\n    if(data_cnt>50000):\n        break\nreview_df = pd.DataFrame(data)\ndata_file.close()\n\nstratify_column = 'stars'\n\n# Create a DataFrame from the 'data' list\n\n# Initialize StratifiedShuffleSplit\nstratified_split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n# Perform the split\nfor train_index, test_index in stratified_split.split(review_df, review_df[stratify_column]):\n    stratified_train_df = review_df.loc[train_index]\n    stratified_test_df = review_df.loc[test_index]\nprint(stratified_test_df.shape)","metadata":{"execution":{"iopub.status.busy":"2023-11-20T16:40:59.445284Z","iopub.execute_input":"2023-11-20T16:40:59.446069Z","iopub.status.idle":"2023-11-20T16:41:00.518493Z","shell.execute_reply.started":"2023-11-20T16:40:59.446035Z","shell.execute_reply":"2023-11-20T16:41:00.517365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display the first few rows of train and test subsets\nprint(\"Train Subset:\")\nprint(stratified_train_df.head())\n\nprint(\"Test Subset:\")\nprint(stratified_test_df.head())\n\n# Check the shape of train and test subsets\nprint(\"Train Subset Shape:\", stratified_train_df.shape)\nprint(\"Test Subset Shape:\", stratified_test_df.shape)\n\n# Summary statistics of the 'stars' column in train and test subsets\nprint(\"Train Subset Statistics:\")\nprint(stratified_train_df['stars'].describe())\n\nprint(\"Test Subset Statistics:\")\nprint(stratified_test_df['stars'].describe())","metadata":{"execution":{"iopub.status.busy":"2023-11-20T16:41:00.519808Z","iopub.execute_input":"2023-11-20T16:41:00.520410Z","iopub.status.idle":"2023-11-20T16:41:00.550426Z","shell.execute_reply.started":"2023-11-20T16:41:00.520378Z","shell.execute_reply":"2023-11-20T16:41:00.549425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Distribution of 'stars' in train and test subsets\nplt.figure(figsize=(10, 5))\nplt.subplot(1, 2, 1)\nsns.countplot(x='stars', data=stratified_train_df)\nplt.title('Train Subset - Distribution of Stars')\n\nplt.subplot(1, 2, 2)\nsns.countplot(x='stars', data=stratified_test_df)\nplt.title('Test Subset - Distribution of Stars')\n\nplt.tight_layout()\nplt.show()\n\n# Selecting numerical columns for correlation analysis\nnumeric_columns = stratified_train_df.select_dtypes(include='number').columns.tolist()\n\n# Correlation matrix for train subset\ntrain_corr = stratified_train_df[numeric_columns].corr()\n\n# Correlation matrix for test subset\ntest_corr = stratified_test_df[numeric_columns].corr()\n\n# Plotting heatmaps\nplt.figure(figsize=(12, 5))\n\nplt.subplot(1, 2, 1)\nsns.heatmap(train_corr, annot=True, cmap='coolwarm')\nplt.title('Train Subset - Correlation Heatmap')\n\nplt.subplot(1, 2, 2)\nsns.heatmap(test_corr, annot=True, cmap='coolwarm')\nplt.title('Test Subset - Correlation Heatmap')\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-20T16:41:00.552647Z","iopub.execute_input":"2023-11-20T16:41:00.552971Z","iopub.status.idle":"2023-11-20T16:41:02.299908Z","shell.execute_reply.started":"2023-11-20T16:41:00.552945Z","shell.execute_reply":"2023-11-20T16:41:02.298632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from wordcloud import WordCloud\n\n# Joining text from train and test subsets\ntrain_text = ' '.join(stratified_train_df['text'].tolist())\ntest_text = ' '.join(stratified_test_df['text'].tolist())\n\n# Creating word clouds for train and test subsets\nwordcloud_train = WordCloud(width=800, height=400, background_color='white').generate(train_text)\nwordcloud_test = WordCloud(width=800, height=400, background_color='white').generate(test_text)\n\n# Plotting word clouds\nplt.figure(figsize=(12, 6))\n\nplt.subplot(1, 2, 1)\nplt.imshow(wordcloud_train, interpolation='bilinear')\nplt.axis('off')\nplt.title('Word Cloud - Train Subset')\n\nplt.subplot(1, 2, 2)\nplt.imshow(wordcloud_test, interpolation='bilinear')\nplt.axis('off')\nplt.title('Word Cloud - Test Subset')\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-20T16:41:02.301359Z","iopub.execute_input":"2023-11-20T16:41:02.301687Z","iopub.status.idle":"2023-11-20T16:41:26.650006Z","shell.execute_reply.started":"2023-11-20T16:41:02.301658Z","shell.execute_reply":"2023-11-20T16:41:26.648736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\n\n# Download NLTK stopwords\nimport nltk\nnltk.download('stopwords')\nnltk.download('punkt')\n\nstop_words = set(stopwords.words('english'))\n\ndef preprocess_text(text):\n    # Convert text to lowercase\n    text = text.lower()\n    \n    # Remove punctuation\n    text = re.sub(r'[^\\w\\s]', '', text)\n    \n    # Tokenize text\n    tokens = word_tokenize(text)\n    \n    # Remove stopwords\n    tokens = [token for token in tokens if token not in stop_words]\n    \n    return tokens\n\n# Apply preprocessing to your DataFrame 'text' column\nstratified_train_df['processed_text'] = stratified_train_df['text'].apply(preprocess_text)\nstratified_test_df['processed_text'] = stratified_test_df['text'].apply(preprocess_text)","metadata":{"execution":{"iopub.status.busy":"2023-11-20T16:41:26.651447Z","iopub.execute_input":"2023-11-20T16:41:26.652044Z","iopub.status.idle":"2023-11-20T16:42:16.217757Z","shell.execute_reply.started":"2023-11-20T16:41:26.652012Z","shell.execute_reply":"2023-11-20T16:42:16.216491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from gensim.models import Word2Vec\n\n# Train Word2Vec model on the processed text data\nmodel_train = Word2Vec(sentences=stratified_train_df['processed_text'], vector_size=100, window=5, min_count=1, workers=4)\nmodel_test = Word2Vec(sentences=stratified_test_df['processed_text'], vector_size=100, window=5, min_count=1, workers=4)\n\n# Accessing word vectors\nword_vectors_train = model_train.wv\nword_vectors_test = model_test.wv\n\n# Getting word vector for a specific word\nvector = word_vectors_train['word']\n\n# Finding similar words\nsimilar_words = word_vectors_train.most_similar('word', topn=5)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-20T16:42:16.219187Z","iopub.execute_input":"2023-11-20T16:42:16.220179Z","iopub.status.idle":"2023-11-20T16:42:33.824900Z","shell.execute_reply.started":"2023-11-20T16:42:16.220138Z","shell.execute_reply":"2023-11-20T16:42:33.823251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(similar_words)","metadata":{"execution":{"iopub.status.busy":"2023-11-20T16:42:33.827018Z","iopub.execute_input":"2023-11-20T16:42:33.827874Z","iopub.status.idle":"2023-11-20T16:42:33.838002Z","shell.execute_reply.started":"2023-11-20T16:42:33.827801Z","shell.execute_reply":"2023-11-20T16:42:33.835095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Decision Tree\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score\nimport numpy as np\n\n# Function to transform text into averaged word vectors\ndef transform_text_to_vectors(text, word_vectors):\n    vectorized_text = []\n    for sentence in text:\n        sentence_vectors = [word_vectors[word] for word in sentence if word in word_vectors]\n        if sentence_vectors:\n            vectorized_text.append(np.mean(sentence_vectors, axis=0))\n        else:\n            # If no word in the sentence is in the word_vectors, append zeros\n            vectorized_text.append(np.zeros(word_vectors.vector_size))\n    return np.array(vectorized_text)\n\n# Transforming text data to numerical vectors\nX_train = transform_text_to_vectors(stratified_train_df['processed_text'], word_vectors_train)\nX_test = transform_text_to_vectors(stratified_test_df['processed_text'], word_vectors_test)\n\ny_train = stratified_train_df['stars']\ny_test = stratified_test_df['stars']\n\n# Initialize Decision Tree Classifier\nclf = DecisionTreeClassifier(random_state=42)\n\n# Train the Decision Tree model\nclf.fit(X_train, y_train)\n\n# Predict on the test set\ny_pred = clf.predict(X_test)\n\n# Calculate accuracy\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Decision Tree Accuracy: {accuracy}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-11-20T17:21:04.858290Z","iopub.execute_input":"2023-11-20T17:21:04.859423Z","iopub.status.idle":"2023-11-20T17:21:24.810660Z","shell.execute_reply.started":"2023-11-20T17:21:04.859377Z","shell.execute_reply":"2023-11-20T17:21:24.808929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Decision Tree with parameters tuned\n\n# from sklearn.model_selection import GridSearchCV\n\n# # Define the hyperparameters grid to search\n# param_grid = {\n#     'max_depth': [None, 5, 10, 15],  # Adjust these values as needed\n#     'min_samples_split': [2, 5, 10],\n#     'min_samples_leaf': [1, 2, 4]\n#     # Add more hyperparameters and their values to explore\n# }\n\n# # Initialize Decision Tree Classifier\n# clf = DecisionTreeClassifier(random_state=42)\n\n# # Initialize GridSearchCV with the defined hyperparameters and cross-validation\n# grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='accuracy')\n\n# # Fit the grid search to the training data\n# grid_search.fit(X_train, y_train)\n\n# # Get the best parameters and the best score\n# best_params = grid_search.best_params_\n# best_score = grid_search.best_score_\n\n# print(f\"Best Parameters: {best_params}\")\n# print(f\"Best Accuracy Score: {best_score}\")\n\n# # Use the best estimator found by GridSearchCV to make predictions\n# best_clf = grid_search.best_estimator_\n# y_pred = best_clf.predict(X_test)\n\n# # Calculate accuracy\n# accuracy = accuracy_score(y_test, y_pred)\n# print(f\"Decision Tree Accuracy after Hyperparameter Tuning: {accuracy}\")","metadata":{"execution":{"iopub.status.busy":"2023-11-20T17:21:26.976453Z","iopub.execute_input":"2023-11-20T17:21:26.976926Z","iopub.status.idle":"2023-11-20T17:29:04.582905Z","shell.execute_reply.started":"2023-11-20T17:21:26.976889Z","shell.execute_reply":"2023-11-20T17:29:04.581199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Forest\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Initialize Random Forest Classifier\nrf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n\n# Train the Random Forest model\nrf_clf.fit(X_train, y_train)\n\n# Predict on the test set\nrf_y_pred = rf_clf.predict(X_test)\n\n# Calculate accuracy\nrf_accuracy = accuracy_score(y_test, rf_y_pred)\nprint(f\"Random Forest Accuracy: {rf_accuracy}\")","metadata":{"execution":{"iopub.status.busy":"2023-11-20T16:42:53.358434Z","iopub.execute_input":"2023-11-20T16:42:53.358811Z","iopub.status.idle":"2023-11-20T16:43:50.479597Z","shell.execute_reply.started":"2023-11-20T16:42:53.358774Z","shell.execute_reply":"2023-11-20T16:43:50.478329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Function to plot confusion matrix\ndef plot_confusion_matrix(y_true, y_pred, title):\n    cm = confusion_matrix(y_true, y_pred)\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n    plt.xlabel('Predicted labels')\n    plt.ylabel('True labels')\n    plt.title(title)\n    plt.show()\n\n# Decision Tree evaluation\nprint(\"Evaluation metrics for Decision Tree Classifier:\")\nprint(\"------------------------------------------------\")\n\n# Confusion matrix and metrics\nplot_confusion_matrix(y_test, y_pred, title=\"Decision Tree Confusion Matrix\")\nprint(\"Classification Report:\")\nprint(classification_report(y_test, y_pred, zero_division=0))  # Setting zero_division=0\n\n# Random Forest evaluation\nprint(\"\\nEvaluation metrics for Random Forest Classifier:\")\nprint(\"------------------------------------------------\")\n\n# Confusion matrix and metrics\nplot_confusion_matrix(y_test, rf_y_pred, title=\"Random Forest Confusion Matrix\")\nprint(\"Classification Report:\")\nprint(classification_report(y_test, rf_y_pred, zero_division=0)) ","metadata":{"execution":{"iopub.status.busy":"2023-11-20T17:29:57.170107Z","iopub.execute_input":"2023-11-20T17:29:57.170588Z","iopub.status.idle":"2023-11-20T17:29:57.825166Z","shell.execute_reply.started":"2023-11-20T17:29:57.170552Z","shell.execute_reply":"2023-11-20T17:29:57.823829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}